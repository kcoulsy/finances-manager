---
description: Testing guidelines using Vitest with emphasis on avoiding mocks and co-locating tests
globs: 
alwaysApply: true
---

# Testing Guidelines

This project uses **Vitest** for testing. Tests should be reliable, maintainable, and test real behavior rather than implementation details.

## File Structure

### Test File Location
- **Always** co-locate test files next to the code they test
- Test files should be named `[filename].test.ts` or `[filename].test.tsx`
- Place test files in the same directory as the code being tested

### Structure Examples

```
✅ Good - Co-located tests
src/features/auth/actions/
├── login.action.ts
└── login.action.test.ts

src/features/shared/components/ui/
├── button.tsx
└── button.test.tsx

src/features/projects/components/
├── project-form.tsx
└── project-form.test.tsx

❌ Bad - Separate test directory
src/features/auth/actions/
└── login.action.ts

src/tests/
└── login.action.test.ts  # Too far from source
```

## Key Principles

### 1. Avoid Mocking Where Possible

**Default to testing real behavior over mocked implementations.**

Mocking should be a last resort, not the default approach. Real tests provide more confidence and catch more bugs.

```typescript
// ✅ Good - Test with real database/client
import { db } from "@/features/shared/lib/db/client";
import { createProjectAction } from "./create-project.action";

describe("createProjectAction", () => {
  it("creates a project in the database", async () => {
    const result = await createProjectAction({
      name: "Test Project",
      description: "Test description",
    });

    // Verify with real database query
    const project = await db.project.findUnique({
      where: { id: result.data?.project.id },
    });

    expect(project).toBeDefined();
    expect(project?.name).toBe("Test Project");
  });
});

// ❌ Bad - Unnecessary mocking
import { db } from "@/features/shared/lib/db/client";
import { createProjectAction } from "./create-project.action";
import { vi } from "vitest";

describe("createProjectAction", () => {
  it("creates a project", async () => {
    vi.spyOn(db.project, "create").mockResolvedValue({
      id: "123",
      name: "Test Project",
    });

    const result = await createProjectAction({
      name: "Test Project",
    });

    // This doesn't actually test if the database works
    expect(result.data?.project.name).toBe("Test Project");
  });
});
```

### When Mocking is Acceptable

Only mock when:
1. **External APIs**: HTTP requests to third-party services
2. **Time-dependent code**: Date/time functions that need specific values
3. **Expensive operations**: File I/O, image processing, etc.
4. **Untestable side effects**: Browser APIs that don't work in Node.js
5. **Testing error paths**: Simulating errors that are hard to reproduce

```typescript
// ✅ Good - Mock external API
import { vi } from "vitest";

describe("sendEmail", () => {
  it("handles API errors gracefully", async () => {
    vi.spyOn(emailService, "send").mockRejectedValue(
      new Error("API rate limit exceeded")
    );

    const result = await sendEmailAction({ to: "test@example.com" });

    expect(result.serverError).toContain("rate limit");
  });
});

// ✅ Good - Mock date for time-dependent tests
import { vi } from "vitest";

describe("isExpired", () => {
  it("returns true for expired dates", () => {
    vi.useFakeTimers();
    vi.setSystemTime(new Date("2024-01-15"));

    const expired = isExpired(new Date("2024-01-01"));

    expect(expired).toBe(true);

    vi.useRealTimers();
  });
});
```

### What NOT to Mock

**Never mock Prisma database operations to simulate errors.**

Mocking Prisma database methods (`db.contact.create`, `db.contact.update`, `db.contact.delete`, etc.) to simulate database errors causes problems:
1. **Breaks subsequent tests**: Spies on Prisma methods can interfere with later tests, causing "is not a function" errors
2. **Not necessary**: Error handling can be tested by using real database operations with invalid data (e.g., non-existent IDs)
3. **Unreliable**: Manual spy cleanup interferes with Vitest's automatic cleanup mechanism
4. **Doesn't test real behavior**: Mocking database operations doesn't test actual database interactions or error handling

```typescript
// ❌ Bad - Don't mock Prisma database errors
it("returns user-friendly error messages for toast display on database errors", async () => {
  vi.spyOn(db.contact, "update").mockRejectedValue(
    new Error("PrismaClientKnownRequestError: P2025")
  );

  const result = await updateContactAction({
    contactId: "test-id",
    // ...
  });

  expect(result.serverError).toBeDefined();
  // This test is unnecessary and causes problems in subsequent tests
});

// ✅ Good - Test error handling with real database operations
it("returns user-friendly error when contact not found", async () => {
  const result = await updateContactAction({
    contactId: "non-existent-id",
    firstName: "Test",
    lastName: "User",
    email: "test@example.com",
    status: "PERSONAL",
  });

  expect(result.serverError).toBeDefined();
  expect(result.serverError?.toLowerCase()).toMatch(/not found|could not find/i);
  // This tests real behavior without mocking
});

// ✅ Good - Test error handling with invalid data
it("returns user-friendly error when email already exists", async () => {
  // Create first contact
  await createContactAction({
    firstName: "First",
    lastName: "User",
    email: "duplicate@example.com",
    status: "PERSONAL",
  });

  // Create second contact
  const secondContact = await createContactAction({
    firstName: "Second",
    lastName: "User",
    email: "other@example.com",
    status: "PERSONAL",
  });

  // Try to update second contact with first contact's email
  const result = await updateContactAction({
    contactId: secondContact.data?.contact.id!,
    firstName: "Second",
    lastName: "User",
    email: "duplicate@example.com", // Already exists
    status: "PERSONAL",
  });

  expect(result.serverError).toBeDefined();
  expect(result.serverError?.toLowerCase()).toMatch(/already exists|email.*exists/i);
  // This tests real database constraint violations
});
```

**Key Principles:**

- **Test real error scenarios**: Use actual database operations with invalid data instead of mocking
- **Test with non-existent IDs**: Use IDs that don't exist to test "not found" error handling
- **Test with constraint violations**: Create real database constraint violations (e.g., duplicate emails) to test error handling
- **Avoid mocking database methods**: Never use `vi.spyOn()` on Prisma database methods (`db.*.*`)
- **Remove unnecessary tests**: If a test only verifies error message formatting and requires mocking, consider removing it

### 2. Test Real User Interactions

Use Testing Library's user-centric queries and interactions rather than testing implementation details.

```typescript
// ✅ Good - Test from user perspective
import { render, screen } from "@testing-library/react";
import userEvent from "@testing-library/user-event";
import { LoginForm } from "./login-form";

describe("LoginForm", () => {
  it("submits form when user enters credentials", async () => {
    const user = userEvent.setup();
    render(<LoginForm />);

    await user.type(screen.getByLabelText(/email/i), "test@example.com");
    await user.type(screen.getByLabelText(/password/i), "password123");
    await user.click(screen.getByRole("button", { name: /sign in/i }));

    await waitFor(() => {
      expect(screen.getByText(/welcome/i)).toBeInTheDocument();
    });
  });
});

// ❌ Bad - Testing implementation details
describe("LoginForm", () => {
  it("calls onSubmit with form data", () => {
    const onSubmit = vi.fn();
    const { container } = render(<LoginForm onSubmit={onSubmit} />);

    const form = container.querySelector("form");
    const emailInput = container.querySelector('input[name="email"]');
    const passwordInput = container.querySelector('input[name="password"]');

    // Testing DOM structure instead of user behavior
    expect(form).toBeInTheDocument();
    expect(emailInput).toBeInTheDocument();
  });
});
```

### 3. Test Behavior, Not Implementation

Focus on what the code does, not how it does it.

```typescript
// ✅ Good - Test behavior
describe("calculateTotal", () => {
  it("calculates correct total with tax", () => {
    const total = calculateTotal(100, 0.1);

    expect(total).toBe(110);
  });
});

// ❌ Bad - Testing implementation details
describe("calculateTotal", () => {
  it("multiplies amount by tax rate and adds amount", () => {
    const spy = vi.spyOn(Math, "multiply");
    calculateTotal(100, 0.1);

    // Testing HOW it calculates instead of WHAT it returns
    expect(spy).toHaveBeenCalled();
  });
});
```

## Testing Patterns

### Server Actions

Test server actions with real database operations when possible:

```typescript
import { db } from "@/features/shared/lib/db/client";
import { createProjectAction } from "./create-project.action";
import { beforeEach, afterEach } from "vitest";

describe("createProjectAction", () => {
  beforeEach(async () => {
    // Clean up before each test
    await db.project.deleteMany();
  });

  afterEach(async () => {
    // Clean up after each test
    await db.project.deleteMany();
  });

  it("creates a project successfully", async () => {
    const result = await createProjectAction({
      name: "New Project",
      description: "Project description",
    });

    expect(result.data?.success).toBe(true);
    expect(result.data?.project).toBeDefined();

    // Verify in database
    const project = await db.project.findUnique({
      where: { id: result.data?.project.id },
    });

    expect(project?.name).toBe("New Project");
  });

  it("validates required fields", async () => {
    const result = await createProjectAction({
      name: "",
      description: "",
    });

    expect(result.validationErrors).toBeDefined();
    expect(result.validationErrors?.fieldErrors?.name).toBeDefined();
  });

  it("returns user-friendly error messages for toast display", async () => {
    // Mock a database error to test error message handling
    vi.spyOn(db.project, "create").mockRejectedValue(
      new Error("PrismaClientKnownRequestError: P2002")
    );

    const result = await createProjectAction({
      name: "Test Project",
      description: "Test description",
    });

    // Test error messages are user-appropriate (not technical)
    expect(result.serverError).toBeDefined();
    expect(result.serverError).not.toContain("PrismaClient");
    expect(result.serverError).not.toContain("P2002");
    expect(result.serverError).not.toContain("Database");
    // Should contain user-friendly message
    expect(result.serverError).toMatch(/unable|failed|error/i);
  });
});
```

### Testing Toast Outputs

**Always test toast outputs when testing server actions** to ensure error messages are user-appropriate and success toasts are properly configured.

#### Testing Error Toast Messages

When testing actions that may throw errors, verify that error messages are user-friendly and appropriate for toast display:

```typescript
import { createProjectAction } from "./create-project.action";
import { vi } from "vitest";

describe("createProjectAction", () => {
  it("returns user-friendly error messages for toast display", async () => {
    // Mock a database error
    vi.spyOn(db.project, "create").mockRejectedValue(
      new Error("PrismaClientKnownRequestError: P2002")
    );

    const result = await createProjectAction({
      name: "Test Project",
      description: "Test description",
    });

    // Verify error message is user-appropriate (not technical)
    expect(result.serverError).toBeDefined();
    expect(result.serverError).not.toContain("PrismaClient");
    expect(result.serverError).not.toContain("P2002");
    expect(result.serverError).not.toContain("Database");
    // Should contain user-friendly message
    expect(result.serverError).toMatch(/unable|failed|error/i);
  });

  it("returns specific user-friendly error for not found", async () => {
    const result = await getProjectAction({
      projectId: "non-existent-id",
    });

    expect(result.serverError).toBeDefined();
    expect(result.serverError?.toLowerCase()).toMatch(/not found|could not find/i);
    // Should not contain technical details
    expect(result.serverError).not.toContain("Prisma");
    expect(result.serverError).not.toContain("undefined");
  });
});
```

#### Testing Success Toast Configuration

When actions return toast configuration, test that it's properly structured:

```typescript
describe("createProjectAction", () => {
  it("returns success toast configuration", async () => {
    const result = await createProjectAction({
      name: "New Project",
      description: "Project description",
    });

    expect(result.data?.success).toBe(true);
    expect(result.data?.toast).toBeDefined();
    expect(result.data?.toast?.message).toBeDefined();
    expect(result.data?.toast?.type).toBe("success");
    expect(result.data?.toast?.message).toContain("Project"); // Should be specific
  });
});
```

#### Testing Both Error and Success Paths

Always test both error and success toast scenarios:

```typescript
describe("updateProjectAction", () => {
  it("returns success toast on successful update", async () => {
    const result = await updateProjectAction({
      projectId: "existing-id",
      name: "Updated Project",
    });

    expect(result.data?.success).toBe(true);
    expect(result.data?.toast?.message).toContain("updated");
    expect(result.data?.toast?.type).toBe("success");
  });

  it("returns user-friendly error toast on failure", async () => {
    const result = await updateProjectAction({
      projectId: "non-existent-id",
      name: "Updated Project",
    });

    expect(result.serverError).toBeDefined();
    // Error message should be user-friendly
    expect(result.serverError?.toLowerCase()).toMatch(/not found|unable|failed/i);
    expect(result.serverError).not.toContain("Prisma");
    expect(result.serverError).not.toContain("P2025");
  });
});
```

#### Key Testing Requirements

When testing toast outputs:

1. **Error Messages**: Always verify error messages are user-friendly:
   - ✅ Good: Test that messages don't contain technical jargon
   - ✅ Good: Test that messages are clear and actionable
   - ❌ Bad: Don't just check that error exists - verify it's appropriate

2. **Success Toasts**: Test that success toast configuration is present and correct:
   - ✅ Good: Verify message, type, and optional description
   - ✅ Good: Test that messages are specific and informative

3. **User-Appropriate**: Verify messages are suitable for end users:
   - ✅ Good: Messages should be clear, actionable, and free of technical details
   - ❌ Bad: Messages should never expose database codes, stack traces, or internal errors

```typescript
// ✅ Good - Comprehensive toast testing
describe("deleteProjectAction", () => {
  it("returns user-friendly error if project not found", async () => {
    const result = await deleteProjectAction({
      projectId: "non-existent-id",
    });

    expect(result.serverError).toBeDefined();
    // Verify user-friendly message
    expect(result.serverError?.toLowerCase()).toMatch(/not found|could not find/i);
    // Verify no technical details
    expect(result.serverError).not.toMatch(/prisma|database|p2025|undefined/i);
  });

  it("returns success toast on successful deletion", async () => {
    // Setup: create a project first
    const project = await createProjectAction({
      name: "Test Project",
      description: "Test",
    });

    const result = await deleteProjectAction({
      projectId: project.data?.project.id!,
    });

    expect(result.data?.success).toBe(true);
    expect(result.data?.toast?.message).toMatch(/deleted|removed/i);
    expect(result.data?.toast?.type).toBe("success");
  });
});
```

### React Components

Test components with real user interactions:

```typescript
import { render, screen } from "@testing-library/react";
import userEvent from "@testing-library/user-event";
import { ProjectForm } from "./project-form";
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";

describe("ProjectForm", () => {
  const queryClient = new QueryClient({
    defaultOptions: { queries: { retry: false } },
  });

  const wrapper = ({ children }: { children: React.ReactNode }) => (
    <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>
  );

  it("renders form fields", () => {
    render(<ProjectForm />, { wrapper });

    expect(screen.getByLabelText(/project name/i)).toBeInTheDocument();
    expect(screen.getByLabelText(/description/i)).toBeInTheDocument();
  });

  it("submits form with valid data", async () => {
    const user = userEvent.setup();
    render(<ProjectForm />, { wrapper });

    await user.type(screen.getByLabelText(/project name/i), "My Project");
    await user.type(
      screen.getByLabelText(/description/i),
      "Project description"
    );
    await user.click(screen.getByRole("button", { name: /create/i }));

    await waitFor(() => {
      expect(screen.getByText(/project created/i)).toBeInTheDocument();
    });
  });
});
```

### Utilities and Helpers

Test pure functions without mocks:

```typescript
import { formatDate, calculateAge } from "./date-utils";

describe("formatDate", () => {
  it("formats date correctly", () => {
    const date = new Date("2024-01-15");
    const formatted = formatDate(date);

    expect(formatted).toBe("January 15, 2024");
  });
});

describe("calculateAge", () => {
  it("calculates age correctly", () => {
    const birthDate = new Date("1990-01-15");
    const today = new Date("2024-01-15");
    
    const age = calculateAge(birthDate, today);

    expect(age).toBe(34);
  });
});
```

### Zod Schemas

Test validation schemas directly:

```typescript
import { projectSchema } from "../schemas/project.schema";

describe("projectSchema", () => {
  it("validates valid project data", () => {
    const validData = {
      name: "Test Project",
      description: "Test description",
    };

    const result = projectSchema.safeParse(validData);

    expect(result.success).toBe(true);
    if (result.success) {
      expect(result.data.name).toBe("Test Project");
    }
  });

  it("rejects invalid project data", () => {
    const invalidData = {
      name: "",
      description: "",
    };

    const result = projectSchema.safeParse(invalidData);

    expect(result.success).toBe(false);
    if (!result.success) {
      expect(result.error.errors).toBeDefined();
    }
  });
});
```

## Test Organization

### Structure Tests by Feature

Organize tests to mirror your feature structure:

```
src/features/projects/
├── actions/
│   ├── create-project.action.ts
│   └── create-project.action.test.ts
├── components/
│   ├── project-form.tsx
│   └── project-form.test.tsx
├── schemas/
│   ├── project.schema.ts
│   └── project.schema.test.ts
└── hooks/
    ├── use-projects.ts
    └── use-projects.test.ts
```

### Test Naming

Use descriptive test names that explain what is being tested:

```typescript
// ✅ Good - Descriptive names
describe("createProjectAction", () => {
  it("creates a project with valid data", async () => {
    // ...
  });

  it("returns validation errors for missing required fields", async () => {
    // ...
  });

  it("handles database connection errors gracefully", async () => {
    // ...
  });
});

// ❌ Bad - Vague names
describe("createProjectAction", () => {
  it("works", async () => {
    // ...
  });

  it("test1", async () => {
    // ...
  });
});
```

## Setup and Teardown

### Database Cleanup

Always clean up test data:

```typescript
import { db } from "@/features/shared/lib/db/client";
import { beforeEach, afterEach } from "vitest";

describe("project actions", () => {
  beforeEach(async () => {
    // Clean state before each test
    await db.project.deleteMany();
  });

  afterEach(async () => {
    // Clean up after each test
    await db.project.deleteMany();
  });
});
```

### Mock and Spy Cleanup

**Always clean up spies and mocks so they don't interfere with subsequent tests.**

When using `vi.spyOn()` or other mocking functions, Vitest automatically cleans up spies after each test completes. However, you should avoid manually calling `mockRestore()` or storing spy references that might interfere with Vitest's automatic cleanup mechanism.

**Key Principles:**

1. **Let Vitest handle cleanup automatically**: Vitest automatically restores spies after each test completes
2. **Don't store spy references unnecessarily**: Only store spy references if you need to access them later in the same test
3. **Never manually restore in try/finally blocks**: This can interfere with Vitest's automatic cleanup and cause problems in subsequent tests
4. **Avoid restoring spies that were auto-cleaned**: Manually restoring an already-cleaned spy can break the original implementation

```typescript
// ✅ Good - Let Vitest handle cleanup automatically
it("returns user-friendly error messages for toast display on database errors", async () => {
  // Create spy without storing reference
  vi.spyOn(db.contact, "update").mockRejectedValue(
    new Error("PrismaClientKnownRequestError: P2025"),
  );

  const result = await updateContactAction({
    contactId: "test-id",
    firstName: "Test",
    lastName: "User",
    email: "test@example.com",
    status: "PERSONAL",
  });

  expect(result.serverError).toBeDefined();
  expect(result.serverError).not.toContain("PrismaClient");
  // Vitest automatically restores the spy after this test completes
});

// ❌ Bad - Manual restore interferes with Vitest's automatic cleanup
it("returns user-friendly error messages for toast display on database errors", async () => {
  const updateSpy = vi.spyOn(db.contact, "update").mockRejectedValue(
    new Error("PrismaClientKnownRequestError: P2025"),
  );

  try {
    const result = await updateContactAction({
      contactId: "test-id",
      firstName: "Test",
      lastName: "User",
      email: "test@example.com",
      status: "PERSONAL",
    });

    expect(result.serverError).toBeDefined();
  } finally {
    // ❌ Don't manually restore - Vitest handles this automatically
    // Manual restore can break the original implementation for subsequent tests
    updateSpy.mockRestore();
  }
});
```

**Why Manual Restore Causes Problems:**

1. **Breaks original implementation**: Calling `mockRestore()` after Vitest has already cleaned up can remove the original function entirely
2. **Race conditions**: Manual restore in `finally` blocks can execute at the wrong time relative to Vitest's cleanup
3. **Interference between tests**: A manually restored spy from one test can break the same function for subsequent tests
4. **Function becomes undefined**: The original function may become `undefined` or `null`, causing errors like "is not a function"

**When You Need Spy References:**

Only store spy references if you need to:
- Assert that the spy was called with specific arguments
- Check call counts within the same test
- Restore only if you need to restore mid-test (rare)

```typescript
// ✅ Good - Store reference only when needed for assertions
it("calls database method with correct arguments", async () => {
  const createSpy = vi.spyOn(db.project, "create");

  await createProjectAction({
    name: "Test Project",
  });

  // Use spy reference for assertions
  expect(createSpy).toHaveBeenCalledWith(
    expect.objectContaining({
      data: expect.objectContaining({
        name: "Test Project",
      }),
    }),
  );
  // Vitest automatically restores after test completes
});
```

**Common Error Pattern:**

```typescript
// ❌ This pattern causes "db.contact.update is not a function" errors
it("test with spy", async () => {
  const spy = vi.spyOn(db.contact, "update").mockRejectedValue(new Error("test"));

  try {
    // Test code
  } finally {
    spy.mockRestore(); // ❌ Breaks for subsequent tests
  }
});

// ✅ Correct pattern - let Vitest handle cleanup
it("test with spy", async () => {
  vi.spyOn(db.contact, "update").mockRejectedValue(new Error("test"));

  // Test code
  // Vitest automatically cleans up after test completes
});
```

**Remember:**

- Vitest automatically restores all spies after each test
- Never manually restore spies unless you have a specific need to restore mid-test
- Manual restore in `finally` blocks causes problems in subsequent tests
- If you see "is not a function" errors, check for manual `mockRestore()` calls

### Test Isolation

Each test should be independent and not rely on other tests:

```typescript
// ✅ Good - Independent tests
describe("calculateTotal", () => {
  it("calculates total for positive amounts", () => {
    expect(calculateTotal(100, 0.1)).toBe(110);
  });

  it("calculates total for zero amount", () => {
    expect(calculateTotal(0, 0.1)).toBe(0);
  });

  it("calculates total for negative amounts", () => {
    expect(calculateTotal(-100, 0.1)).toBe(-110);
  });
});

// ❌ Bad - Tests depend on each other
describe("calculateTotal", () => {
  let result: number;

  it("calculates total", () => {
    result = calculateTotal(100, 0.1);
    expect(result).toBe(110);
  });

  it("uses previous result", () => {
    // Depends on previous test
    expect(result).toBe(110);
  });
});
```

### Test Independence and Race Conditions

**Tests must be completely independent of each other. There should never be a situation where one test causes a race condition or removes data that another test needs.**

Key principles:
1. **Each test is responsible for its own setup**: Tests should create all the data they need in their own `beforeEach` or at the start of the test
2. **Cleanup should not interfere with test execution**: Cleanup should only happen in `afterEach`, not in `beforeEach` where it might delete data needed by the test
3. **No shared state between tests**: Tests should not rely on data created by other tests, even in the same file
4. **Test files should be isolated**: One test file's cleanup should never affect another test file's execution

```typescript
// ✅ Good - Cleanup only in afterEach, data creation in beforeEach
describe("createProjectAction", () => {
  setupTestHooks(); // Sets up cleanup in afterEach

  beforeEach(async () => {
    // Create data needed for this test
    testUser = await setupTestUserWithSession();
  });

  afterEach(async () => {
    // Cleanup happens here, after test completes
    // This ensures cleanup doesn't interfere with test execution
  });
});

// ❌ Bad - Cleanup in beforeEach interferes with test execution
describe("createProjectAction", () => {
  beforeEach(async () => {
    await cleanupTestData(); // ❌ This deletes data before test can use it
    testUser = await setupTestUserWithSession();
  });
});
```

**When using `setupTestHooks()`:**
- `setupTestHooks()` does NOT clean up data - it only initializes mocks
- `beforeAll` only resets mocks - it does NOT cleanup data
- `beforeEach` only initializes headers mock - it does NOT cleanup data
- Always create data in your test file's `beforeEach` AFTER `setupTestHooks()` is called
- Cleanup happens in two places only:
  1. **Global setup** (`src/features/shared/testing/setup.ts`) - runs once at the start of the entire test suite
  2. **Global teardown** (`src/features/shared/testing/teardown.ts`) - runs once after ALL test files complete
- This prevents cleanup from interfering between test files or individual tests
- If a test needs to delete data (e.g., for error testing), create it fresh in that test itself
- Tests must never rely on data from other tests, even in the same file
- Each test should be completely isolated - cleanup should never interfere with test execution
- **Never put cleanup in `beforeEach` or `afterEach`** - this causes race conditions and data deletion between tests

## Best Practices

### 1. Prefer Integration Tests

Integration tests test multiple units working together and catch more bugs:

```typescript
// ✅ Good - Integration test
describe("createProjectFlow", () => {
  it("creates project end-to-end", async () => {
    const result = await createProjectAction({
      name: "Test Project",
    });

    // Test action, database, and validation together
    expect(result.data?.success).toBe(true);

    const project = await db.project.findUnique({
      where: { id: result.data?.project.id },
    });

    expect(project).toBeDefined();
  });
});
```

### 2. Test Error Cases

Always test error paths and edge cases:

```typescript
describe("getProjectAction", () => {
  it("returns project when found", async () => {
    // ...
  });

  it("returns error when project not found", async () => {
    const result = await getProjectAction({
      projectId: "non-existent-id",
    });

    expect(result.serverError).toBeDefined();
  });

  it("validates project ID format", async () => {
    const result = await getProjectAction({
      projectId: "",
    });

    expect(result.validationErrors).toBeDefined();
  });
});
```

### 3. Use Descriptive Assertions

Make test failures easy to understand:

```typescript
// ✅ Good - Clear assertions
expect(project.name).toBe("Test Project");
expect(result.data?.success).toBe(true);
expect(screen.getByRole("button", { name: /submit/i })).toBeDisabled();

// ❌ Bad - Hard to debug
expect(result).toBeDefined();
expect(project).toBeTruthy();
expect(button).toBeInTheDocument();
```

### 4. Never Wrap Expects in If Statements

**Always write direct assertions. Never wrap `expect` calls in conditional statements.**

Conditional assertions hide test failures and make debugging difficult. Use non-null assertions or type narrowing if needed.

```typescript
// ✅ Good - Direct assertions with non-null assertion
expect(notFoundError).not.toBeNull();
expect(
  notFoundError!.message.includes("NEXT_NOT_FOUND") ||
    notFoundError!.message.includes("Unauthorized"),
).toBe(true);

// ✅ Good - Direct assertions after type narrowing with expect
expect(result).toBeDefined();
expect(result.data?.success).toBe(true);

// ❌ Bad - Wrapped in if statement (hides failures)
expect(notFoundError).toBeDefined();
if (notFoundError) {
  expect(
    notFoundError.message.includes("NEXT_NOT_FOUND") ||
      notFoundError.message.includes("Unauthorized"),
  ).toBe(true);
}

// ❌ Bad - Conditional assertion
if (result) {
  expect(result.data?.success).toBe(true);
}
```

**When to use non-null assertions:**
- After asserting that a value is not null/undefined, use `!` operator to tell TypeScript the value is safe
- Example: `expect(error).not.toBeNull(); expect(error!.message).toContain("error");`

**Note:** The only exception is when using type guards with `safeParse` from Zod, where you need to check the `success` property before accessing `data` or `error`.

### 5. Keep Tests Fast

- Use in-memory database for tests when possible
- Avoid unnecessary waits and timeouts
- Clean up resources promptly

### 6. Test Accessibility

Use accessibility-focused queries from Testing Library:

```typescript
// ✅ Good - Accessibility-focused queries
screen.getByRole("button", { name: /submit/i });
screen.getByLabelText(/email address/i);
screen.getByText(/welcome/i);

// ❌ Bad - Implementation-focused queries
container.querySelector("button");
container.querySelector('input[name="email"]');
```

## Running Tests

### Use Vitest MCP Server

**Always use the Vitest MCP server instead of terminal commands when running tests from the agent.**

The Vitest MCP server provides:
- Structured test results with detailed output
- Better integration with the codebase
- Automatic project root detection
- Optimized test execution

```typescript
// ✅ Good - Use Vitest MCP server
import { mcp_vitest_set_project_root, mcp_vitest_run_tests } from "@/mcp-tools";

// Set project root first
await mcp_vitest_set_project_root({
  path: "/absolute/path/to/project"
});

// Run tests for specific files or directories
await mcp_vitest_run_tests({
  target: "src/features/projects/actions/update-project.action.test.ts",
  format: "detailed", // or "summary"
  showLogs: false // Set to true to see console output
});

// ❌ Bad - Don't use terminal commands
run_terminal_cmd({
  command: "npm test -- src/features/projects/actions/update-project.action.test.ts"
});
```

**Key Points:**
1. **Always set project root first** using `mcp_vitest_set_project_root` before running tests
2. **Use detailed format** when debugging failures, summary format for quick checks
3. **Enable showLogs** (`showLogs: true`) when you need to see console output from tests
4. **Target specific files or directories** using relative paths from project root
5. **Prefer MCP server over terminal** - provides better structured output and integration

### Test the Whole Suite After Individual Tests

**Always run the entire test suite after individual tests pass to ensure they don't conflict with each other.**

When writing or modifying tests:
1. **First**: Run individual test files to verify they pass in isolation
2. **Then**: Run the entire test suite to ensure tests don't interfere with each other
3. **Fix any conflicts**: If tests pass individually but fail when run together, investigate:
   - Shared state between tests
   - Cleanup interfering with other tests
   - Race conditions from cleanup happening at wrong times
   - Missing isolation in test setup

```typescript
// ✅ Good - Test workflow
// 1. Run individual test file
await mcp_vitest_run_tests({
  target: "src/features/projects/actions/create-project.action.test.ts",
  format: "detailed"
});

// 2. After individual tests pass, run entire suite
await mcp_vitest_run_tests({
  target: "src/features/projects/actions", // or entire test suite
  format: "detailed"
});

// ❌ Bad - Only testing individual files
// Tests might pass individually but fail when run together
await mcp_vitest_run_tests({
  target: "src/features/projects/actions/create-project.action.test.ts"
});
// Missing: Not testing the whole suite to catch conflicts
```

**Why This Matters:**
- Individual tests might pass because cleanup happens between files
- Tests might interfere with each other if cleanup happens at wrong times
- Shared state or race conditions only appear when multiple test files run together
- Ensures test isolation and prevents flaky tests

**Common Issues to Watch For:**
- Foreign key constraint violations when one test file's cleanup deletes data another test needs
- Tests passing individually but failing in the suite due to cleanup timing
- Race conditions from cleanup happening in `beforeAll` of each test file
- Tests relying on data from previous test files

### Test Commands (Manual Testing)

For manual testing outside the agent, you can still use terminal commands:

```bash
# Run tests in watch mode (development)
npm test

# Run tests once (CI)
npm run test:run

# Run tests with UI
npm run test:ui

# Run tests with coverage
npm run test:coverage
```

## Common Patterns

### Testing Server Components

Server components should be tested with real data fetching:

```typescript
import { render } from "@testing-library/react";
import { ProjectsPage } from "./page";

describe("ProjectsPage", () => {
  it("displays projects from database", async () => {
    // Use real database
    const projects = await getProjectsAction();
    
    const { container } = await render(ProjectsPage({ projects }));
    
    expect(container).toHaveTextContent(projects[0].name);
  });
});
```

### Testing Client Components with Hooks

Wrap components with necessary providers:

```typescript
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";
import { render } from "@testing-library/react";

const createWrapper = () => {
  const queryClient = new QueryClient({
    defaultOptions: { queries: { retry: false } },
  });

  return ({ children }: { children: React.ReactNode }) => (
    <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>
  );
};

describe("ProjectsList", () => {
  it("renders projects", () => {
    render(<ProjectsList />, { wrapper: createWrapper() });
    // ...
  });
});
```

## Anti-Patterns to Avoid

### ❌ Over-Mocking

Don't mock everything - it defeats the purpose of testing:

```typescript
// ❌ Bad - Over-mocking
vi.spyOn(db.project, "create").mockResolvedValue({});
vi.spyOn(db.project, "findUnique").mockResolvedValue({});
vi.spyOn(auth, "getSession").mockResolvedValue({});

// This doesn't test anything real
```

### ❌ Testing Implementation Details

Don't test HOW code works, test WHAT it does:

```typescript
// ❌ Bad - Testing internals
expect(component.state.isLoading).toBe(true);
expect(fn.mock.calls.length).toBe(1);

// ✅ Good - Testing behavior
expect(screen.getByText(/loading/i)).toBeInTheDocument();
expect(screen.getByText(/success/i)).toBeInTheDocument();
```

### ❌ Brittle Tests

Don't write tests that break when implementation changes:

```typescript
// ❌ Bad - Brittle
expect(container.querySelector("div > div > button")).toBeInTheDocument();

// ✅ Good - Robust
expect(screen.getByRole("button", { name: /submit/i })).toBeInTheDocument();
```

## Summary

1. **Co-locate tests** with the code they test
2. **Avoid mocking** - test real behavior when possible
3. **Test user interactions** - use Testing Library's user-centric APIs
4. **Test behavior** - focus on what code does, not how
5. **Test error cases** - don't just test happy paths
6. **Keep tests independent** - each test should stand alone
7. **Use descriptive names** - make test failures easy to understand
8. **Clean up test data** - use beforeEach/afterEach for cleanup
